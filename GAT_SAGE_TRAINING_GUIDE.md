# Training GAT and GraphSAGE Models - Recovery Guide

## é—®é¢˜èƒŒæ™¯

åœ¨è®­ç»ƒ5ä¸ªYelpæ¨¡å‹æ—¶ï¼ŒGCN-1ã€GCN-2å’ŒGCN-3æˆåŠŸå®Œæˆï¼Œä½†GATå’ŒGraphSAGEç”±äºGPUå†…å­˜ä¸è¶³ï¼ˆOOMï¼‰å¤±è´¥ï¼š

```
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 26.62 GiB.
```

## è§£å†³æ–¹æ¡ˆ

åˆ›å»ºäº†ä¸“é—¨çš„è®­ç»ƒè„šæœ¬å’ŒSLURMä½œä¸šæ¥å®Œæˆå‰©ä½™æ¨¡å‹çš„è®­ç»ƒï¼Œé‡‡ç”¨ä»¥ä¸‹å†…å­˜ä¼˜åŒ–ç­–ç•¥ï¼š

### å†…å­˜ä¼˜åŒ–æªæ–½

1. **å‡å°‘éšè—å±‚ç»´åº¦**ï¼šä»64é™åˆ°32
2. **å‡å°‘GATæ³¨æ„åŠ›å¤´æ•°**ï¼šä»8é™åˆ°2
3. **å¢åŠ ç³»ç»Ÿå†…å­˜**ï¼šä»64GBå¢åŠ åˆ°128GB
4. **ç§¯æçš„å†…å­˜æ¸…ç†**ï¼šåœ¨æ¯ä¸ªepochåæ¸…ç†GPUç¼“å­˜
5. **æ›´å°çš„å†…å­˜åˆ†é…å—**ï¼š`PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:256`

## æ–‡ä»¶è¯´æ˜

### 1. `src/Train_Yelp_HPC_GAT_SAGE.py`

ä¸“é—¨è®­ç»ƒGATå’ŒGraphSAGEçš„è„šæœ¬ï¼ŒåŒ…å«ï¼š

- **å†…å­˜ä¼˜åŒ–çš„æ¨¡å‹å®šä¹‰**
  - GAT: 2ä¸ªattention headsï¼ˆåŸæ¥æ˜¯8ä¸ªï¼‰
  - GraphSAGE: æ ‡å‡†é…ç½®ä½†ä½¿ç”¨æ›´å°çš„hidden_dim
  
- **å†…å­˜ç®¡ç†åŠŸèƒ½**
  - è‡ªåŠ¨GPUå†…å­˜æ¸…ç†
  - è¯¦ç»†çš„å†…å­˜ä½¿ç”¨ç›‘æ§
  - OOMé”™è¯¯æ•è·å’Œæ¢å¤

- **é…ç½®å‚æ•°**
  ```python
  config = {
      'hidden_dim': 32,      # å‡å°‘å†…å­˜ä½¿ç”¨
      'lr': 0.005,           # ç¨ä½çš„å­¦ä¹ ç‡
      'weight_decay': 5e-4,
      'epochs': 200,
      'patience': 50,
  }
  ```

### 2. `train_yelp_gat_sage.slurm`

SLURMä½œä¸šè„šæœ¬ï¼Œé…ç½®ï¼š

- **èµ„æºè¯·æ±‚**
  - GPU: 1ä¸ª
  - CPU: 8æ ¸
  - å†…å­˜: **128GB**ï¼ˆå¢åŠ äº†ä¸€å€ï¼‰
  - æ—¶é—´: 48å°æ—¶

- **ç¯å¢ƒå˜é‡**
  ```bash
  export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:256
  export OMP_NUM_THREADS=8
  ```

## ä½¿ç”¨æ­¥éª¤

### æ­¥éª¤1: ä¸Šä¼ æ–°æ–‡ä»¶åˆ°HPC

```bash
# åœ¨æœ¬åœ°æ‰§è¡Œ
cd ~/Desktop/Research/GroundingGEXP

# åªä¸Šä¼ æ–°æ–‡ä»¶
scp src/Train_Yelp_HPC_GAT_SAGE.py username@hpc:/path/to/GroundingGEXP/src/
scp train_yelp_gat_sage.slurm username@hpc:/path/to/GroundingGEXP/
```

æˆ–è€…ä¸Šä¼ æ•´ä¸ªé¡¹ç›®ï¼ˆå¦‚æœå·²ç»æ›´æ–°äº†å…¶ä»–æ–‡ä»¶ï¼‰ï¼š

```bash
rsync -avz --progress \
  --exclude='datasets/*' \
  --exclude='results/*' \
  --exclude='__pycache__' \
  GroundingGEXP/ username@hpc:/path/to/GroundingGEXP/
```

### æ­¥éª¤2: åœ¨HPCä¸Šä¿®æ”¹SLURMè„šæœ¬

```bash
# SSHç™»å½•HPC
ssh username@hpc

# è¿›å…¥é¡¹ç›®ç›®å½•
cd /path/to/GroundingGEXP

# ç¼–è¾‘SLURMè„šæœ¬
nano train_yelp_gat_sage.slurm
```

**å¿…é¡»ä¿®æ”¹çš„å†…å®¹ï¼š**

```bash
#SBATCH --partition=gpu          # æ”¹ä¸ºä½ çš„GPUåˆ†åŒºå
#SBATCH --mail-user=your@email.com   # æ”¹ä¸ºä½ çš„é‚®ç®±

# å¦‚æœä½ çš„HPCæ¨¡å—åä¸åŒï¼Œä¿®æ”¹è¿™é‡Œï¼š
module load Miniconda3
source activate skyexp
```

### æ­¥éª¤3: æäº¤ä½œä¸š

```bash
# æäº¤ä½œä¸š
sbatch train_yelp_gat_sage.slurm

# æŸ¥çœ‹ä½œä¸šçŠ¶æ€
squeue -u $USER

# å®æ—¶ç›‘æ§æ—¥å¿—
tail -f logs/yelp_gat_sage_*.out
```

### æ­¥éª¤4: ç›‘æ§è®­ç»ƒè¿›åº¦

```bash
# æŸ¥çœ‹æ ‡å‡†è¾“å‡º
tail -f logs/yelp_gat_sage_<JOBID>.out

# æŸ¥çœ‹é”™è¯¯æ—¥å¿—ï¼ˆå¦‚æœæœ‰ï¼‰
tail -f logs/yelp_gat_sage_<JOBID>.err

# æ£€æŸ¥GPUä½¿ç”¨
nvidia-smi

# æŸ¥çœ‹ä½œä¸šè¯¦æƒ…
scontrol show job <JOBID>
```

## é¢„æœŸè¾“å‡º

### è®­ç»ƒè¿‡ç¨‹

```
======================================================================
YELP DATASET - GAT & GraphSAGE TRAINING
======================================================================
Device: cuda:0
PyTorch version: 2.0.0
CUDA version: 11.8
GPU: NVIDIA A100-SXM4-40GB
GPU Memory: 40.00 GB
======================================================================

Loading Yelp dataset...
Dataset loaded in 45.23 seconds

Dataset Statistics:
  Nodes: 716,847
  Edges: 13,954,819
  Features: 300
  Classes: 100
  Multi-label: True
  Train nodes: 466,952
  Val nodes: 116,738
  Test nodes: 133,157

######################################################################
# MODEL 1/2: GAT 3-layer
######################################################################

GPU Memory before training:
  Allocated: 0.52 GB
  Reserved: 0.98 GB

Model parameters: 45,300

======================================================================
Training gat on Yelp (Multi-label: True)
======================================================================
Epochs: 200, LR: 0.005, Weight Decay: 0.0005
Device: cuda:0
Patience: 50
======================================================================

Data successfully moved to GPU

Epoch 001 | Loss: 0.6923 | Train: 0.0012/0.4521 | Val: 0.0008/0.4498 | Test: 0.0009/0.4495
  â†’ Saved best model (val_hamming: 0.4498)
Epoch 010 | Loss: 0.2341 | Train: 0.0234/0.7821 | Val: 0.0198/0.7651 | Test: 0.0201/0.7675
  â†’ Saved best model (val_hamming: 0.7651)
...
```

### æˆåŠŸå®Œæˆ

```
======================================================================
Training completed in 35.67 minutes
Best epoch: 142
Best validation hamming: 0.8534
Final test exact match: 0.0189
Final test hamming: 0.8467
======================================================================

âœ“ GAT training completed successfully!

GPU Memory after cleanup:
  Allocated: 0.02 GB
  Reserved: 0.50 GB

######################################################################
# MODEL 2/2: GraphSAGE 3-layer
######################################################################

...

======================================================================
TRAINING SUMMARY
======================================================================
Total training time: 4234.56 seconds (70.58 minutes)
Successful models: 2/2
======================================================================

Model           Layers     Params       Val Metric   Test Hamming Time (min)
----------------------------------------------------------------------
GAT             3-layer    45,300       0.8534       0.8467       35.67
SAGE            3-layer    40,164       0.8512       0.8445       34.91
======================================================================

Results saved to: models/Yelp_GAT_SAGE_training_results.json

âœ“ Successfully trained 2 model(s)!
Models saved in: models/
  - models/Yelp_gat_model.pth
  - models/Yelp_sage_model.pth

======================================================================
Training script completed!
======================================================================
```

## ç»“æœéªŒè¯

è®­ç»ƒå®Œæˆåï¼Œæ£€æŸ¥æ¨¡å‹æ–‡ä»¶ï¼š

```bash
# åœ¨HPCä¸Šæ‰§è¡Œ
ls -lh models/Yelp_*.pth

# åº”è¯¥çœ‹åˆ°æ‰€æœ‰5ä¸ªæ¨¡å‹ï¼š
# Yelp_gcn1_model.pth   (å·²æœ‰ï¼Œæ¥è‡ªç¬¬ä¸€æ¬¡è®­ç»ƒ)
# Yelp_gcn2_model.pth   (å·²æœ‰ï¼Œæ¥è‡ªç¬¬ä¸€æ¬¡è®­ç»ƒ)
# Yelp_gcn_model.pth    (å·²æœ‰ï¼Œæ¥è‡ªç¬¬ä¸€æ¬¡è®­ç»ƒ)
# Yelp_gat_model.pth    (æ–°è®­ç»ƒçš„)
# Yelp_sage_model.pth   (æ–°è®­ç»ƒçš„)

# æ£€æŸ¥è®­ç»ƒç»“æœ
cat models/Yelp_GAT_SAGE_training_results.json
```

## ä¸‹è½½æ¨¡å‹

```bash
# ä»æœ¬åœ°æœºå™¨æ‰§è¡Œ
cd ~/Desktop/Research/GroundingGEXP

# ä¸‹è½½æ–°è®­ç»ƒçš„æ¨¡å‹
scp username@hpc:/path/to/GroundingGEXP/models/Yelp_gat_model.pth ./models/
scp username@hpc:/path/to/GroundingGEXP/models/Yelp_sage_model.pth ./models/

# æˆ–è€…ä¸‹è½½æ•´ä¸ªmodelsç›®å½•
scp -r username@hpc:/path/to/GroundingGEXP/models/ ./
```

## é¢„æœŸè®­ç»ƒæ—¶é—´

### GPU (NVIDIA A100/V100)
- **GAT**: ~30-40åˆ†é’Ÿ
- **GraphSAGE**: ~30-40åˆ†é’Ÿ
- **æ€»è®¡**: ~1-1.5å°æ—¶

### å¦‚æœä»ç„¶OOM

å¦‚æœå³ä½¿ä½¿ç”¨å†…å­˜ä¼˜åŒ–åä»ç„¶OOMï¼Œå¯ä»¥å°è¯•ï¼š

### æ–¹æ¡ˆA: è¿›ä¸€æ­¥å‡å°‘å‚æ•°

ç¼–è¾‘ `src/Train_Yelp_HPC_GAT_SAGE.py`ï¼š

```python
config = {
    'hidden_dim': 16,  # ä»32è¿›ä¸€æ­¥é™åˆ°16
    ...
}

# å¯¹äºGAT
model = model_class(input_dim, hidden_dim, output_dim, heads=1)  # æ”¹ä¸º1ä¸ªå¤´
```

### æ–¹æ¡ˆB: ä½¿ç”¨CPUè®­ç»ƒ

åˆ›å»ºCPUç‰ˆæœ¬çš„SLURMè„šæœ¬ï¼š

```bash
cp train_yelp_gat_sage.slurm train_yelp_gat_sage_cpu.slurm
```

ä¿®æ”¹ï¼š
```bash
#SBATCH --partition=cpu        # æ”¹ä¸ºCPUåˆ†åŒº
#SBATCH --gres=                # åˆ é™¤GPUè¯·æ±‚
#SBATCH --cpus-per-task=16     # å¢åŠ CPUæ ¸å¿ƒ
#SBATCH --mem=256G             # å¢åŠ å†…å­˜
#SBATCH --time=96:00:00        # å¢åŠ æ—¶é—´ï¼ˆCPUæ›´æ…¢ï¼‰
```

åœ¨è„šæœ¬ä¸­æ³¨é‡Šæ‰CUDAæ¨¡å—ï¼š
```bash
# module load cuda/11.8
# module load cudnn/8.6
```

### æ–¹æ¡ˆC: ä½¿ç”¨æ›´å¤§GPU

å¦‚æœä½ çš„HPCæœ‰æ›´å¤§å†…å­˜çš„GPUï¼ˆå¦‚A100 80GBï¼‰ï¼Œå¯ä»¥è¯·æ±‚ï¼š

```bash
#SBATCH --gres=gpu:a100-80gb:1
# æˆ–
#SBATCH --constraint=gpu_mem:80GB
```

## æ•…éšœæ’æŸ¥

### é—®é¢˜1: ä»ç„¶OOM

**æ£€æŸ¥**ï¼š
```bash
tail logs/yelp_gat_sage_*.err
```

**è§£å†³**ï¼š
1. ä½¿ç”¨æ–¹æ¡ˆAå‡å°‘hidden_dimåˆ°16
2. GATåªä½¿ç”¨1ä¸ªattention head
3. ä½¿ç”¨CPUè®­ç»ƒï¼ˆæ…¢ä½†ç¨³å®šï¼‰

### é—®é¢˜2: æ•°æ®é›†ä¸‹è½½å¤±è´¥

**ç—‡çŠ¶**ï¼š`ConnectionError` æˆ– `TimeoutError`

**è§£å†³**ï¼š
```bash
# ä»ç¬¬ä¸€æ¬¡è®­ç»ƒä¸­å¤åˆ¶æ•°æ®é›†
cp -r datasets/Yelp datasets_backup/
```

### é—®é¢˜3: æ¨¡å—åŠ è½½å¤±è´¥

**æ£€æŸ¥å¯ç”¨æ¨¡å—**ï¼š
```bash
module avail python
module avail cuda
```

**ä¿®æ”¹SLURMè„šæœ¬**ï¼š
```bash
module load python/3.9  # æˆ–ä½ HPCå¯ç”¨çš„ç‰ˆæœ¬
module load cuda/11.7   # æˆ–ä½ HPCå¯ç”¨çš„ç‰ˆæœ¬
```

## å®Œæˆåçš„æ£€æŸ¥æ¸…å•

- [ ] ä¸¤ä¸ªæ¨¡å‹éƒ½æˆåŠŸè®­ç»ƒå®Œæˆ
- [ ] `models/Yelp_gat_model.pth` å­˜åœ¨ä¸”å¤§äº1MB
- [ ] `models/Yelp_sage_model.pth` å­˜åœ¨ä¸”å¤§äº1MB
- [ ] `models/Yelp_GAT_SAGE_training_results.json` å­˜åœ¨
- [ ] JSONæ–‡ä»¶ä¸­ `"success": true` å¯¹äºä¸¤ä¸ªæ¨¡å‹
- [ ] å·²ä¸‹è½½æ¨¡å‹åˆ°æœ¬åœ°
- [ ] å·²å¤‡ä»½è®­ç»ƒæ—¥å¿—

## ä¸‹ä¸€æ­¥

å®ŒæˆGATå’ŒGraphSAGEè®­ç»ƒåï¼Œä½ å°†æ‹¥æœ‰æ‰€æœ‰5ä¸ªYelpæ¨¡å‹ï¼š

```
models/
â”œâ”€â”€ Yelp_gcn1_model.pth      âœ“
â”œâ”€â”€ Yelp_gcn2_model.pth      âœ“
â”œâ”€â”€ Yelp_gcn_model.pth       âœ“
â”œâ”€â”€ Yelp_gat_model.pth       âœ“ (æ–°)
â””â”€â”€ Yelp_sage_model.pth      âœ“ (æ–°)
```

æ¥ä¸‹æ¥å¯ä»¥ï¼š

1. **å®šä¹‰Yelpçº¦æŸ**ï¼šåˆ›å»ºTGDçº¦æŸç”¨äºè§£é‡Š
2. **é€‚é…è§£é‡Šç®—æ³•**ï¼šä¿®æ”¹ApxChase/HeuChaseæ”¯æŒèŠ‚ç‚¹çº§è§£é‡Š
3. **è¿è¡Œè§£é‡Šå®éªŒ**ï¼šå¯¹ç›®æ ‡èŠ‚ç‚¹ç”Ÿæˆè§£é‡Š
4. **è®¡ç®—æŒ‡æ ‡**ï¼šFidelity-, Conciseness, Coverage

## å¿«é€Ÿå‘½ä»¤å‚è€ƒ

```bash
# ä¸Šä¼ æ–‡ä»¶
scp src/Train_Yelp_HPC_GAT_SAGE.py train_yelp_gat_sage.slurm username@hpc:GroundingGEXP/

# æäº¤ä½œä¸š
sbatch train_yelp_gat_sage.slurm

# ç›‘æ§
tail -f logs/yelp_gat_sage_*.out

# æ£€æŸ¥ç»“æœ
ls -lh models/Yelp_{gat,sage}_model.pth

# ä¸‹è½½
scp username@hpc:GroundingGEXP/models/Yelp_{gat,sage}_model.pth models/
```

---

**ç¥è®­ç»ƒé¡ºåˆ©ï¼** ğŸš€

å¦‚æœé‡åˆ°ä»»ä½•é—®é¢˜ï¼Œè¯·æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶æˆ–è”ç³»HPCæ”¯æŒå›¢é˜Ÿã€‚
