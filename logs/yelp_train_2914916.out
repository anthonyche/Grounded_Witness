==========================================
Job started at: Sat Oct 11 23:11:29 EDT 2025
Job ID: 2914916
Running on node: gput055
==========================================

System Information:
  Hostname: gput055
  CPU cores: 8
  Memory: 65536 MB
  GPU: 0

Loaded modules:

Currently Loaded Modules:
  1) Miniconda3/23.10.0-1

 


Python Environment:
/home/hxc859/.conda/envs/skyexp/bin/python
Python 3.10.16

PyTorch Information:
PyTorch version: 2.3.0+cu121
CUDA available: True
CUDA version: 12.1

Working directory: /home/hxc859/Grounding_EXP

==========================================
Starting Yelp GNN Training...
==========================================

======================================================================
YELP DATASET - GCN TRAINING (1/2/3 layers)
======================================================================
Device: cuda
PyTorch version: 2.3.0+cu121
CUDA version: 12.1
GPU: Tesla V100-SXM2-32GB
GPU Memory: 34.07 GB
======================================================================

Loading Yelp dataset...
Dataset loaded in 3.58 seconds

Dataset Statistics:
  Nodes: 716,847
  Edges: 13,954,819
  Features: 300
  Classes: 100
  Multi-label: True
  Train nodes: 537,635
  Val nodes: 107,527
  Test nodes: 71,685


######################################################################
# MODEL 1/3: GCN 1-layer
######################################################################

GPU Memory before training:
  Allocated: 0.00 GB
  Reserved: 0.00 GB

Model parameters: 30,100

======================================================================
Training gcn1 on Yelp (Multi-label: True)
======================================================================
Epochs: 200, LR: 0.005, Weight Decay: 0.0005
Device: cuda
Patience: 50
======================================================================

Data successfully moved to GPU
Epoch 001 | Loss: 0.6907 | Train: 0.0065/0.8906 | Val: 0.0063/0.8913 | Test: 0.0063/0.8912
  → Saved best model (val_hamming: 0.8913)
Epoch 010 | Loss: 0.6701 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
  → Saved best model (val_hamming: 0.9109)
Epoch 020 | Loss: 0.6486 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 030 | Loss: 0.6289 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 040 | Loss: 0.6110 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 050 | Loss: 0.5947 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 060 | Loss: 0.5794 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 070 | Loss: 0.5648 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 080 | Loss: 0.5508 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 090 | Loss: 0.5376 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 100 | Loss: 0.5250 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 110 | Loss: 0.5132 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 120 | Loss: 0.5020 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 130 | Loss: 0.4914 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 140 | Loss: 0.4814 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 150 | Loss: 0.4719 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 160 | Loss: 0.4630 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 170 | Loss: 0.4545 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 180 | Loss: 0.4466 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 190 | Loss: 0.4390 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 200 | Loss: 0.4319 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108

======================================================================
Training completed in 0.55 minutes
Best epoch: 10
Best validation hamming: 0.9109
Final test exact match: 0.0184
Final test hamming: 0.9108
======================================================================

✓ GCN1 training completed successfully!

GPU Memory after cleanup:
  Allocated: 1.39 GB
  Reserved: 1.41 GB


######################################################################
# MODEL 2/3: GCN 2-layer
######################################################################

GPU Memory before training:
  Allocated: 1.39 GB
  Reserved: 1.41 GB

Model parameters: 12,932

======================================================================
Training gcn2 on Yelp (Multi-label: True)
======================================================================
Epochs: 200, LR: 0.005, Weight Decay: 0.0005
Device: cuda
Patience: 50
======================================================================

Data successfully moved to GPU
Epoch 001 | Loss: 0.6907 | Train: 0.0103/0.8903 | Val: 0.0097/0.8908 | Test: 0.0104/0.8910
  → Saved best model (val_hamming: 0.8908)
Epoch 010 | Loss: 0.6634 | Train: 0.0186/0.9102 | Val: 0.0172/0.9109 | Test: 0.0183/0.9108
  → Saved best model (val_hamming: 0.9109)
Epoch 020 | Loss: 0.6045 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
  → Saved best model (val_hamming: 0.9109)
Epoch 030 | Loss: 0.5134 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 040 | Loss: 0.4161 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 050 | Loss: 0.3528 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 060 | Loss: 0.3257 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 070 | Loss: 0.3149 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 080 | Loss: 0.3096 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 090 | Loss: 0.3062 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 100 | Loss: 0.3039 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 110 | Loss: 0.3023 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 120 | Loss: 0.3011 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 130 | Loss: 0.3001 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 140 | Loss: 0.2993 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 150 | Loss: 0.2988 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 160 | Loss: 0.2983 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 170 | Loss: 0.2979 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 180 | Loss: 0.2975 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 190 | Loss: 0.2972 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 200 | Loss: 0.2969 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108

======================================================================
Training completed in 0.65 minutes
Best epoch: 20
Best validation hamming: 0.9109
Final test exact match: 0.0184
Final test hamming: 0.9108
======================================================================

✓ GCN2 training completed successfully!

GPU Memory after cleanup:
  Allocated: 1.39 GB
  Reserved: 1.41 GB


######################################################################
# MODEL 3/3: GCN 3-layer
######################################################################

GPU Memory before training:
  Allocated: 1.39 GB
  Reserved: 1.41 GB

Model parameters: 13,988

======================================================================
Training gcn3 on Yelp (Multi-label: True)
======================================================================
Epochs: 200, LR: 0.005, Weight Decay: 0.0005
Device: cuda
Patience: 50
======================================================================

Data successfully moved to GPU
Epoch 001 | Loss: 0.6907 | Train: 0.0057/0.8690 | Val: 0.0058/0.8696 | Test: 0.0055/0.8697
  → Saved best model (val_hamming: 0.8696)
Epoch 010 | Loss: 0.6579 | Train: 0.0186/0.9102 | Val: 0.0172/0.9108 | Test: 0.0183/0.9107
  → Saved best model (val_hamming: 0.9108)
Epoch 020 | Loss: 0.5537 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
  → Saved best model (val_hamming: 0.9109)
Epoch 030 | Loss: 0.3763 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 040 | Loss: 0.3250 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 050 | Loss: 0.3129 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 060 | Loss: 0.3121 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 070 | Loss: 0.3093 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 080 | Loss: 0.3084 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 090 | Loss: 0.3078 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 100 | Loss: 0.3071 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 110 | Loss: 0.3067 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 120 | Loss: 0.3064 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 130 | Loss: 0.3060 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 140 | Loss: 0.3057 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 150 | Loss: 0.3054 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 160 | Loss: 0.3051 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 170 | Loss: 0.3047 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 180 | Loss: 0.3044 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 190 | Loss: 0.3040 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 200 | Loss: 0.3035 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108

======================================================================
Training completed in 0.80 minutes
Best epoch: 20
Best validation hamming: 0.9109
Final test exact match: 0.0184
Final test hamming: 0.9108
======================================================================

✓ GCN3 training completed successfully!

GPU Memory after cleanup:
  Allocated: 1.39 GB
  Reserved: 1.41 GB


======================================================================
TRAINING SUMMARY
======================================================================
Total training time: 120.95 seconds (2.02 minutes)
Successful models: 3/3
======================================================================

Model           Layers     Params       Val Metric   Test Hamming Time (min)  
------------------------------------------------------------------------------------------
GCN1            GCN 1-layer 30,100       0.9109       0.9108       0.55        
GCN2            GCN 2-layer 12,932       0.9109       0.9108       0.65        
GCN3            GCN 3-layer 13,988       0.9109       0.9108       0.80        
==========================================================================================

Results saved to: models/Yelp_GCN_training_results.json

✓ Successfully trained 3 model(s)!
Models saved in: models/
  - models/Yelp_gcn1_model.pth
  - models/Yelp_gcn2_model.pth
  - models/Yelp_gcn3_model.pth

======================================================================
Training script completed!
======================================================================

==========================================
Training completed successfully!
Job finished at: Sat Oct 11 23:14:28 EDT 2025
==========================================

Disk usage in models/:
1.6M	models/

Generated model files:
-rw-r----- 1 hxc859 yxw1650 183K Oct 11 23:10 models/Yelp_gat_model.pth
-rw-r----- 1 hxc859 yxw1650 357K Oct 11 23:12 models/Yelp_gcn1_model.pth
-rw-r----- 1 hxc859 yxw1650 158K Oct 11 23:13 models/Yelp_gcn2_model.pth
-rw-r----- 1 hxc859 yxw1650 172K Oct 11 23:13 models/Yelp_gcn3_model.pth
-rw-r----- 1 hxc859 yxw1650 338K Oct 11 23:10 models/Yelp_sage_model.pth

