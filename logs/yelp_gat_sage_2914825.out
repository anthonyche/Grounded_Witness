==========================================
Job started at: Sat Oct 11 20:30:14 EDT 2025
Job ID: 2914825
Running on node: gput064
==========================================

System Information:
  Hostname: gput064
  CPU cores: 8
  Memory: 131072 MB
  GPU: 0

Loaded modules:

Currently Loaded Modules:
  1) Miniconda3/23.10.0-1

 


Python Environment:
/home/hxc859/.conda/envs/skyexp/bin/python
Python 3.10.16

PyTorch Information:
PyTorch version: 2.3.0+cu121
CUDA available: True
CUDA version: 12.1
Device count: 1

GPU Information:
name, memory.total [MiB], memory.free [MiB]
NVIDIA L40S, 46068 MiB, 45469 MiB

Working directory: /home/hxc859/Grounding_EXP

Checking existing models:
-rw-r----- 1 hxc859 yxw1650 120K Oct 11 20:17 models/Yelp_gcn1_model.pth
-rw-r----- 1 hxc859 yxw1650 103K Oct 11 20:17 models/Yelp_gcn2_model.pth
-rw-r----- 1 hxc859 yxw1650 120K Oct 11 20:18 models/Yelp_gcn_model.pth

==========================================
Starting GAT & GraphSAGE Training...
==========================================

======================================================================
YELP DATASET - GAT & GraphSAGE TRAINING
======================================================================
Device: cuda
PyTorch version: 2.3.0+cu121
CUDA version: 12.1
GPU: NVIDIA L40S
GPU Memory: 47.68 GB
======================================================================

Loading Yelp dataset...
Dataset loaded in 1.43 seconds

Dataset Statistics:
  Nodes: 716,847
  Edges: 13,954,819
  Features: 300
  Classes: 100
  Multi-label: True
  Train nodes: 537,635
  Val nodes: 107,527
  Test nodes: 71,685


######################################################################
# MODEL 1/2: GAT 3-layer
######################################################################

GPU Memory before training:
  Allocated: 0.00 GB
  Reserved: 0.00 GB

Model parameters: 14,316

======================================================================
Training gat on Yelp (Multi-label: True)
======================================================================
Epochs: 200, LR: 0.005, Weight Decay: 0.0005
Device: cuda
Patience: 50
======================================================================

Data successfully moved to GPU
Epoch 001 | Loss: 0.6893 | Train: 0.0000/0.8039 | Val: 0.0000/0.8043 | Test: 0.0000/0.8043
  → Saved best model (val_hamming: 0.8043)
Epoch 010 | Loss: 0.5943 | Train: 0.0000/0.8817 | Val: 0.0000/0.8823 | Test: 0.0000/0.8821
  → Saved best model (val_hamming: 0.8823)
Epoch 020 | Loss: 0.3407 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
  → Saved best model (val_hamming: 0.9109)
Epoch 030 | Loss: 0.2860 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 040 | Loss: 0.2701 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 050 | Loss: 0.2684 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 060 | Loss: 0.2703 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 070 | Loss: 0.2685 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 080 | Loss: 0.2682 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 090 | Loss: 0.2686 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 100 | Loss: 0.2685 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 110 | Loss: 0.2686 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 120 | Loss: 0.2686 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 130 | Loss: 0.2686 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 140 | Loss: 0.2686 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 150 | Loss: 0.2686 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 160 | Loss: 0.2686 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 170 | Loss: 0.2685 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 180 | Loss: 0.2685 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 190 | Loss: 0.2685 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 200 | Loss: 0.2685 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108

======================================================================
Training completed in 4.30 minutes
Best epoch: 20
Best validation hamming: 0.9109
Final test exact match: 0.0184
Final test hamming: 0.9108
======================================================================

✓ GAT training completed successfully!

GPU Memory after cleanup:
  Allocated: 0.00 GB
  Reserved: 0.00 GB


######################################################################
# MODEL 2/2: GraphSAGE 3-layer
######################################################################

GPU Memory before training:
  Allocated: 0.00 GB
  Reserved: 0.00 GB

Model parameters: 27,812

======================================================================
Training sage on Yelp (Multi-label: True)
======================================================================
Epochs: 200, LR: 0.005, Weight Decay: 0.0005
Device: cuda
Patience: 50
======================================================================

Data successfully moved to GPU
Epoch 001 | Loss: 0.6875 | Train: 0.0000/0.5721 | Val: 0.0000/0.5722 | Test: 0.0000/0.5723
  → Saved best model (val_hamming: 0.5722)
Epoch 010 | Loss: 0.5305 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
  → Saved best model (val_hamming: 0.9109)
Epoch 020 | Loss: 0.2983 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 030 | Loss: 0.2705 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 040 | Loss: 0.2710 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 050 | Loss: 0.2679 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 060 | Loss: 0.2677 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 070 | Loss: 0.2670 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 080 | Loss: 0.2670 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 090 | Loss: 0.2670 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 100 | Loss: 0.2669 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 110 | Loss: 0.2669 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 120 | Loss: 0.2669 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 130 | Loss: 0.2669 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 140 | Loss: 0.2669 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 150 | Loss: 0.2669 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 160 | Loss: 0.2669 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 170 | Loss: 0.2669 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 180 | Loss: 0.2669 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 190 | Loss: 0.2669 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108
Epoch 200 | Loss: 0.2669 | Train: 0.0187/0.9103 | Val: 0.0173/0.9109 | Test: 0.0184/0.9108

======================================================================
Training completed in 2.15 minutes
Best epoch: 10
Best validation hamming: 0.9109
Final test exact match: 0.0184
Final test hamming: 0.9108
======================================================================

✓ SAGE training completed successfully!

GPU Memory after cleanup:
  Allocated: 0.00 GB
  Reserved: 0.00 GB


======================================================================
TRAINING SUMMARY
======================================================================
Total training time: 388.88 seconds (6.48 minutes)
Successful models: 2/2
======================================================================

Model           Layers     Params       Val Metric   Test Hamming Time (min)  
----------------------------------------------------------------------
GAT             GAT 3-layer 14,316       0.9109       0.9108       4.30        
SAGE            GraphSAGE 3-layer 27,812       0.9109       0.9108       2.15        
======================================================================

Results saved to: models/Yelp_GAT_SAGE_training_results.json

✓ Successfully trained 2 model(s)!
Models saved in: models/
  - models/Yelp_gat_model.pth
  - models/Yelp_sage_model.pth

======================================================================
Training script completed!
======================================================================

==========================================
Training completed successfully!
Job finished at: Sat Oct 11 20:37:01 EDT 2025
==========================================

Disk usage in models/:
1.2M	models/

All model files in models/:
-rw-r----- 1 hxc859 yxw1650 183K Oct 11 20:30 models/Yelp_gat_model.pth
-rw-r----- 1 hxc859 yxw1650 120K Oct 11 20:17 models/Yelp_gcn1_model.pth
-rw-r----- 1 hxc859 yxw1650 103K Oct 11 20:17 models/Yelp_gcn2_model.pth
-rw-r----- 1 hxc859 yxw1650 120K Oct 11 20:18 models/Yelp_gcn_model.pth
-rw-r----- 1 hxc859 yxw1650 338K Oct 11 20:34 models/Yelp_sage_model.pth

GAT and SAGE models:
-rw-r----- 1 hxc859 yxw1650 183K Oct 11 20:30 models/Yelp_gat_model.pth
-rw-r----- 1 hxc859 yxw1650 338K Oct 11 20:34 models/Yelp_sage_model.pth

Training results summary:
{
  "timestamp": "2025-10-11 20:37:00",
  "total_time": 388.87759709358215,
  "config": {
    "data_root": "./datasets",
    "epochs": 200,
    "lr": 0.005,
    "weight_decay": 0.0005,
    "hidden_dim": 32,
    "patience": 50
  },
  "models": [
    {
      "model_name": "gat",
      "training_time": 258.0974612236023,
      "best_epoch": 20,
      "best_val_metric": 0.910926342010498,
      "test_exact": 0.01837204396724701,
      "test_hamming": 0.9107977747917175,
      "success": true,
      "error": null
    },
    {
      "model_name": "sage",
      "training_time": 129.00984358787537,
      "best_epoch": 10,
      "best_val_metric": 0.910926342010498,
      "test_exact": 0.01837204396724701,
      "test_hamming": 0.9107977747917175,
      "success": true,
      "error": null
    }
  ],
  "successful_models": [
    "gat",
    "sage"
  ],
  "failed_models": []
}
Final GPU Memory Usage:
memory.used [MiB], memory.total [MiB]
0 MiB, 46068 MiB

