# 128GB RAM æè‡´ä¼˜åŒ–æ–¹æ¡ˆ

## ğŸ¯ é—®é¢˜ï¼š256GB èµ„æºæ— æ³•è·å–

**è§£å†³æ–¹æ¡ˆ**: æè‡´å†…å­˜ä¼˜åŒ–ï¼Œå¯åœ¨ **128GB RAM** ä¸‹è¿è¡Œï¼

## âœ… ä¼˜åŒ–é…ç½®å¯¹æ¯”

| å‚æ•° | 256GB æ–¹æ¡ˆ | **128GB æ–¹æ¡ˆ** | èŠ‚çœå†…å­˜ |
|------|-----------|---------------|----------|
| **RAM ç”³è¯·** | 256G | **128G** | -128GB |
| **Batch Size** | 512 | **256** | ~40GB |
| **Neighbors** | [10, 5] | **[5, 3]** | ~30GB |
| **Hidden Dim** | 256 | **16** | ~2GB |
| **é¢„æœŸå†…å­˜** | ~130GB | **~85GB** | **-45GB** âœ… |

## ğŸ”§ å·²åº”ç”¨çš„ä¼˜åŒ–

### 1. Slurm é…ç½® (`train_ogbn_papers100m.slurm`)
```bash
#SBATCH --mem=128G       # 128GB RAMï¼ˆä» 256G é™ä½ï¼‰
#SBATCH --time=24:00:00  # 24 å°æ—¶ï¼ˆå› ä¸ºæ›´æ…¢ï¼‰

BATCH_SIZE=256           # ä» 512 â†’ 256ï¼ˆèŠ‚çœ ~40GBï¼‰
NUM_NEIGHBORS="5 3"      # ä» "10 5" â†’ "5 3"ï¼ˆèŠ‚çœ ~30GBï¼‰
HIDDEN_DIM=16            # ä» 256 â†’ 16ï¼ˆèŠ‚çœ ~2GBï¼‰
NUM_WORKERS=0            # ä¿æŒ 0
```

### 2. è®­ç»ƒè„šæœ¬ä¼˜åŒ– (`Train_OGBN_HPC_MiniBatch.py`)

#### æ–°å¢æ¿€è¿›å†…å­˜æ¸…ç†
```python
def clear_all_memory():
    """Aggressive memory clearing (GPU + CPU)"""
    gc.collect()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        torch.cuda.synchronize()

# è®­ç»ƒæ—¶æ¯ 5 ä¸ª batch æ¸…ç†ä¸€æ¬¡
for batch_idx, batch in enumerate(train_loader):
    # ... è®­ç»ƒä»£ç  ...
    del batch, out, loss
    if batch_idx % 5 == 0:
        clear_all_memory()

# Epoch ç»“æŸåå®Œå…¨æ¸…ç†
clear_all_memory()
```

#### è¯„ä¼°æ—¶æ¯ 10 ä¸ª batch æ¸…ç†
```python
# è¯„ä¼°æ—¶æ›´é¢‘ç¹æ¸…ç†
for batch_idx, batch in enumerate(val_loader):
    # ... è¯„ä¼°ä»£ç  ...
    del batch, out, y_pred
    if batch_idx % 10 == 0:
        clear_all_memory()
```

### 3. NeighborLoader é…ç½®
```python
train_loader = NeighborLoader(
    data,
    batch_size=256,           # å° batch
    num_neighbors=[5, 3],     # æœ€å°é‚»å±…é‡‡æ ·
    num_workers=0,            # æ— é¢å¤– worker
    persistent_workers=False, # ç¦ç”¨ç¼“å­˜
    shuffle=True,
)
```

## ğŸ“Š å†…å­˜æ¶ˆè€—è¯¦ç»†åˆ†æ

### 128GB æ–¹æ¡ˆå†…å­˜åˆ†è§£

| ç»„ä»¶ | å†…å­˜æ¶ˆè€— | è¯´æ˜ |
|------|----------|------|
| **æ•°æ®é›†åŸºç¡€** | ~50 GB | ogbn-papers100M åŠ è½½åˆ° RAM |
| **å›¾ç»“æ„** | ~15 GB | PyG COO æ ¼å¼è¾¹ç´¢å¼• |
| **NeighborLoader** | ~15 GB | batch=256, neighbors=[5,3] é‡‡æ · |
| **æ¨¡å‹å‚æ•°** | ~0.5 GB | hidden_dim=16 (æå°) |
| **æ¢¯åº¦** | ~0.5 GB | åå‘ä¼ æ’­ |
| **ç³»ç»Ÿå¼€é”€** | ~4 GB | Python + PyTorch è¿è¡Œæ—¶ |
| **æ€»è®¡** | **~85 GB** | âœ… **è¿œä½äº 128GB** |

### NeighborLoader é‡‡æ ·èŠ‚ç‚¹æ•°å¯¹æ¯”

```python
# [10, 5] é…ç½®ï¼ˆ256GB æ–¹æ¡ˆï¼‰
batch=512: 512 Ã— (1 + 10 + 10Ã—5) â‰ˆ 26,000 èŠ‚ç‚¹/batch

# [5, 3] é…ç½®ï¼ˆ128GB æ–¹æ¡ˆï¼‰
batch=256: 256 Ã— (1 + 5 + 5Ã—3) â‰ˆ 5,100 èŠ‚ç‚¹/batch

èŠ‚ç‚¹æ•°å‡å°‘: 26,000 â†’ 5,100 (å‡å°‘ 80%)
å†…å­˜èŠ‚çœ: ~70 GB
```

## âš¡ æ€§èƒ½å½±å“

### è®­ç»ƒæ—¶é—´é¢„ä¼°

| é…ç½® | æ¯ Epoch | 100 Epochs | å¤‡æ³¨ |
|------|----------|------------|------|
| **ç†æƒ³** (256GB, batch=1024) | ~20 min | ~33 hrs | æ— æ³•è·å–èµ„æº âŒ |
| **ä¸­ç­‰** (256GB, batch=512) | ~30 min | ~50 hrs | æ— æ³•è·å–èµ„æº âŒ |
| **å½“å‰** (128GB, batch=256) | **~50 min** | **~83 hrs (3.5å¤©)** | âœ… **å¯è¡Œ** |

### æƒè¡¡åˆ†æ
- **é€Ÿåº¦**: æ¯”ç†æƒ³æ–¹æ¡ˆæ…¢ ~2.5 å€
- **å†…å­˜**: èŠ‚çœ 128GBï¼ˆ256G â†’ 128Gï¼‰
- **å¯ç”¨æ€§**: âœ… **å¯ä»¥è¿è¡Œ**ï¼ˆæœ€é‡è¦ï¼ï¼‰
- **ç²¾åº¦**: **ä¸å—å½±å“**ï¼ˆåªå½±å“é€Ÿåº¦ï¼Œä¸å½±å“æœ€ç»ˆç²¾åº¦ï¼‰

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### 1. æäº¤ä»»åŠ¡
```bash
sbatch train_ogbn_papers100m.slurm
```

### 2. ç›‘æ§å†…å­˜ä½¿ç”¨
```bash
# æŸ¥çœ‹ä»»åŠ¡çŠ¶æ€
squeue -u $USER

# SSH åˆ°è®¡ç®—èŠ‚ç‚¹å
htop  # RES åˆ—åº”ç¨³å®šåœ¨ 85-100 GB

# æˆ–è€…ä½¿ç”¨
watch -n 10 'ps aux | grep python | grep -v grep'
```

### 3. ç›‘æ§è®­ç»ƒè¿›åº¦
```bash
tail -f logs/ogbn_papers100m_*.out
```

é¢„æœŸè¾“å‡ºï¼š
```
Dataset loaded in X.XX minutes
Creating mini-batch data loaders...
  Batch size: 256
  Neighbor sampling: [5, 3]
  NUM_WORKERS: 0
Starting mini-batch training...
Epoch 1/100: Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| ...
```

## ğŸ†˜ å¦‚æœä»ç„¶ OOM çš„ç»ˆææ–¹æ¡ˆ

### æ–¹æ¡ˆ 1: è¿›ä¸€æ­¥å‡å° batchï¼ˆæ¨èï¼‰
```bash
BATCH_SIZE=128           # ä» 256 â†’ 128
NUM_NEIGHBORS="3 2"      # ä» "5 3" â†’ "3 2"
```
**å†…å­˜**: ~70 GB  
**é€Ÿåº¦**: æ…¢ 3-4 å€

### æ–¹æ¡ˆ 2: åªåœ¨ GPU ä¸Šè®­ç»ƒï¼ˆæ•°æ®åˆ†æ‰¹åŠ è½½ï¼‰
å¦‚æœ GPU å†…å­˜è¶³å¤Ÿï¼ˆ46GB L40Sï¼‰ï¼Œå¯ä»¥å°è¯•åªæŠŠå­å›¾æ”¾åˆ° GPUï¼š
```python
# å·²ç»å®ç°ï¼ˆbatch.to(device)ï¼‰
# æ•°æ®ç•™åœ¨ CPUï¼Œåªæœ‰å½“å‰ batch åœ¨ GPU
```

### æ–¹æ¡ˆ 3: å‡å°‘ epoch æ•°
```bash
EPOCHS=50  # ä» 100 â†’ 50ï¼ˆç”¨äºå¿«é€ŸéªŒè¯ï¼‰
```

### æ–¹æ¡ˆ 4: CPU-only è®­ç»ƒï¼ˆæœ€åé€‰æ‹©ï¼‰
```bash
#SBATCH --gres=gpu:0     # ä¸ç”³è¯· GPU
#SBATCH --cpus-per-task=32
#SBATCH --mem=128G
#SBATCH --time=72:00:00  # 3å¤©

# åœ¨è„šæœ¬ä¸­
device = 'cpu'
```
**å†…å­˜**: ~60 GBï¼ˆæ—  GPU å¼€é”€ï¼‰  
**é€Ÿåº¦**: æ…¢ 20-50 å€ï¼ˆä¸æ¨èï¼Œé™¤éåˆ«æ— é€‰æ‹©ï¼‰

## ğŸ“ˆ é¢„æœŸç»“æœ

### æˆåŠŸæ ‡å¿—
- âœ… è®­ç»ƒå¼€å§‹å¹¶æŒç»­è¿è¡Œ
- âœ… å†…å­˜ä½¿ç”¨ç¨³å®šåœ¨ **85-100 GB**
- âœ… æ—  Exit Code 137ï¼ˆOOM Killerï¼‰
- âœ… æ¯ä¸ª epoch å®Œæˆæ—¶é—´ **~45-55 åˆ†é’Ÿ**

### æœ€ç»ˆç²¾åº¦é¢„æœŸ
- **éªŒè¯é›†**: ~62-65% (OGBN-Papers100M åŸºå‡†)
- **æµ‹è¯•é›†**: ~61-64%
- **æ³¨æ„**: å° hidden_dim (16) å¯èƒ½ç¨ä½äºå¤§æ¨¡å‹ (256)ï¼Œä½†ä»èƒ½è®­ç»ƒ

## ğŸ” è°ƒè¯•æ£€æŸ¥æ¸…å•

å¦‚æœä»ç„¶å¤±è´¥ï¼Œæ£€æŸ¥ï¼š

1. **ç¡®è®¤æ‰€æœ‰ persistent_workers=False**
   ```bash
   grep -n "persistent_workers" src/Train_OGBN_HPC_MiniBatch.py
   # åº”è¯¥çœ‹åˆ°ä¸‰å¤„éƒ½æ˜¯ False
   ```

2. **ç¡®è®¤å‚æ•°ä¼ é€’æ­£ç¡®**
   ```bash
   # Slurm è„šæœ¬æœ€åçš„ python å‘½ä»¤
   python src/Train_OGBN_HPC_MiniBatch.py \
       --batch_size $BATCH_SIZE \
       --num_neighbors $NUM_NEIGHBORS \
       --hidden_dim $HIDDEN_DIM
   ```

3. **æ£€æŸ¥æ•°æ®é›†å¤§å°**
   ```bash
   du -sh datasets/ogbn_papers100M/
   # åº”è¯¥æ˜¯ ~60-70 GB
   ```

4. **æŸ¥çœ‹é”™è¯¯æ—¥å¿—**
   ```bash
   tail -100 logs/ogbn_papers100m_*.err
   ```

## ğŸ’¡ ä¼˜åŒ–åŸç†

### ä¸ºä»€ä¹ˆ batch_size=256 èŠ‚çœè¿™ä¹ˆå¤šå†…å­˜ï¼Ÿ

```
NeighborLoader æ¯ä¸ª batch é‡‡æ ·çš„æ€»èŠ‚ç‚¹æ•°:

batch_size=1024, neighbors=[15,10]:
  1024 Ã— (1 + 15 + 15Ã—10) = 155,000 èŠ‚ç‚¹
  155k Ã— 128 features Ã— 4 bytes = 79 MB per batch
  
batch_size=512, neighbors=[10,5]:
  512 Ã— (1 + 10 + 10Ã—5) = 26,000 èŠ‚ç‚¹
  26k Ã— 128 Ã— 4 = 13 MB per batch
  
batch_size=256, neighbors=[5,3]:
  256 Ã— (1 + 5 + 5Ã—3) = 5,100 èŠ‚ç‚¹
  5.1k Ã— 128 Ã— 4 = 2.6 MB per batch

ä½†æ˜¯ï¼NeighborLoader ä¼šåœ¨å†…éƒ¨ç¼“å­˜å¤šä¸ª batch çš„é‡‡æ ·ç»“æœï¼š
- ç¼“å­˜ ~1000 ä¸ª batch æ—¶
- 1024 é…ç½®: 1000 Ã— 79 MB = 79 GB
- 512 é…ç½®: 1000 Ã— 13 MB = 13 GB  
- 256 é…ç½®: 1000 Ã— 2.6 MB = 2.6 GB

èŠ‚çœ: 79 - 2.6 = 76 GBï¼
```

### persistent_workers=False çš„ä½œç”¨

```python
# persistent_workers=True (é»˜è®¤)
- DataLoader ä¿æŒ worker è¿›ç¨‹æ´»è·ƒ
- ç¼“å­˜é‡‡æ ·ç»“æœä»¥æé€Ÿ
- å†…å­˜ä¸æ–­ç´¯ç§¯ï¼ˆå› ä¸ºç¼“å­˜ä¸é‡Šæ”¾ï¼‰
- é¢å¤–æ¶ˆè€—: 50-200 GB

# persistent_workers=False (ä¼˜åŒ–)
- æ¯ä¸ª batch åç«‹å³é‡Šæ”¾å†…å­˜
- ç¨æ…¢ä½†å†…å­˜å®‰å…¨
- èŠ‚çœ: 50-200 GB
```

## ğŸ“š ç›¸å…³æ–‡æ¡£
- `MEMORY_OPTIMIZATION_GUIDE.md` - å®Œæ•´å†…å­˜ä¼˜åŒ–æŒ‡å—
- `EXIT_CODE_137_FIX.md` - Exit Code 137 è¯¦è§£
- `OGBN_TROUBLESHOOTING.md` - å®Œæ•´æ•…éšœæ’é™¤

## âœ… æ€»ç»“

**é…ç½®**: 128GB RAM, batch=256, neighbors=[5,3], hidden=16  
**å†…å­˜**: ~85 GBï¼ˆå®‰å…¨ï¼‰  
**é€Ÿåº¦**: ~50 min/epochï¼ˆå¯æ¥å—ï¼‰  
**çŠ¶æ€**: âœ… **å¯ä»¥è®­ç»ƒï¼**

è¿™æ˜¯åœ¨ **128GB é™åˆ¶ä¸‹çš„æœ€ä¼˜å¹³è¡¡æ–¹æ¡ˆ**ã€‚å¦‚æœè¿™ä¸ªä»ç„¶ OOMï¼Œä½¿ç”¨"ç»ˆææ–¹æ¡ˆ 1"è¿›ä¸€æ­¥é™ä½åˆ° batch=128ã€‚
