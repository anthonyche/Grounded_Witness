# PGExplainer ç¼“å­˜é—®é¢˜ä¿®æ­£

## é—®é¢˜å‘ç°

ç”¨æˆ·æŒ‡å‡ºäº†ä¸€ä¸ª**å…³é”®çš„è®¾è®¡é”™è¯¯**ï¼š

### åŸå§‹å®ç°ï¼ˆé”™è¯¯ï¼‰
```python
pg_result = run_pgexplainer_node(
    model=model_cpu,
    data=subgraph_cpu,
    use_cache=True,  # âŒ é”™è¯¯ï¼
)
```

**é—®é¢˜**ï¼š
1. Worker 0 çš„ Task 1ï¼šåœ¨å­å›¾ A ä¸Šè®­ç»ƒ PGExplainer â†’ ç¼“å­˜
2. Worker 0 çš„ Task 2ï¼šä½¿ç”¨ç¼“å­˜çš„ explainerï¼ˆè®­ç»ƒè‡ªå­å›¾ Aï¼‰å»è§£é‡Šå­å›¾ B âŒ
3. **è¿™æ˜¯é”™è¯¯çš„ï¼** å­å›¾ A å’Œå­å›¾ B ç»“æ„å®Œå…¨ä¸åŒ

### ä¸ºä»€ä¹ˆç¼“å­˜æ˜¯é”™è¯¯çš„ï¼Ÿ

PGExplainer æ˜¯**å‚æ•°åŒ–**è§£é‡Šå™¨ï¼Œéœ€è¦åœ¨**ç‰¹å®šå›¾ç»“æ„**ä¸Šè®­ç»ƒï¼š
- è¾“å…¥ï¼šå›¾ç»“æ„ + æ¨¡å‹
- è®­ç»ƒï¼šå­¦ä¹ è¾¹æƒé‡æ©ç 
- è¾“å‡ºï¼šé’ˆå¯¹è¯¥å›¾ç»“æ„çš„è§£é‡Š

**ä¸åŒå­å›¾ â†’ ä¸åŒç»“æ„ â†’ éœ€è¦ä¸åŒçš„è®­ç»ƒ**

ç±»æ¯”ï¼š
- âŒ é”™è¯¯ï¼šåœ¨å›¾ç‰‡ A ä¸Šè®­ç»ƒ CNNï¼Œç„¶åç”¨å®ƒè¯†åˆ«å›¾ç‰‡ B
- âœ… æ­£ç¡®ï¼šå¯¹æ¯å¼ å›¾ç‰‡ç‹¬ç«‹è®­ç»ƒ/æ¨ç†

## æ­£ç¡®çš„å®ç°æ–¹å¼

æœ‰ä¸¤ç§åˆç†æ–¹æ¡ˆï¼š

### æ–¹æ¡ˆ Aï¼šæ¯ä¸ªå­å›¾ç‹¬ç«‹è®­ç»ƒï¼ˆå½“å‰é‡‡ç”¨ï¼‰âœ…

```python
pg_result = run_pgexplainer_node(
    model=model_cpu,
    data=subgraph_cpu,  # å½“å‰å­å›¾
    use_cache=False,     # âœ… ç¦ç”¨ç¼“å­˜ï¼šæ¯ä¸ªå­å›¾ç‹¬ç«‹è®­ç»ƒ
)
```

**ç‰¹ç‚¹**ï¼š
- âœ… æ­£ç¡®æ€§ï¼šæ¯ä¸ªå­å›¾ç‹¬ç«‹è®­ç»ƒï¼Œç»“æœå¯é 
- âœ… çœŸæ­£å¹¶è¡Œï¼š20 workers åŒæ—¶è®­ç»ƒä¸åŒå­å›¾
- âš ï¸ æ—¶é—´ï¼šæ¯ä¸ªä»»åŠ¡ ~15-20ç§’ï¼ˆåŒ…å«è®­ç»ƒï¼‰

**é€‚ç”¨åœºæ™¯**ï¼š
- å­å›¾ç»“æ„å·®å¼‚å¤§
- éœ€è¦ç²¾ç¡®çš„è§£é‡Š
- æœ‰è¶³å¤Ÿçš„è®¡ç®—èµ„æºï¼ˆ20 workersï¼‰

### æ–¹æ¡ˆ Bï¼šåœ¨å¤§å›¾ä¸Šé›†ä¸­è®­ç»ƒï¼ˆå¤‡é€‰ï¼‰

```python
# åœ¨ Coordinator ä¸­ï¼ˆmain processï¼‰
def main():
    # ... load data and model ...
    
    # Train PGExplainer once on full graph
    print("Training PGExplainer on full TreeCycle graph...")
    full_graph = torch.load('datasets/TreeCycle/treecycle_d5_bf15_n813616.pt')
    
    from baselines import PGExplainerNodeCache
    global_pg_explainer = PGExplainerNodeCache(
        model=model,
        full_data=full_graph,
        device='cpu',
        epochs=100,  # More epochs for full graph
        lr=0.003
    )
    
    # Serialize and pass to workers
    model_state['pg_explainer'] = global_pg_explainer
    
    # In worker:
    pg_explainer = model_state['pg_explainer']
    explanation, out, target_label = pg_explainer.explain(subgraph, target_node)
```

**ç‰¹ç‚¹**ï¼š
- âœ… å¿«é€Ÿï¼šæ¯ä¸ªä»»åŠ¡ <1ç§’ï¼ˆåªåšæ¨ç†ï¼‰
- âœ… æ‰€æœ‰æ—¶é—´éƒ½æ˜¯ training overheadï¼ˆä¸€æ¬¡æ€§ï¼‰
- âš ï¸ å¯èƒ½ä¸å‡†ç¡®ï¼šåœ¨å¤§å›¾ä¸Šè®­ç»ƒï¼Œåº”ç”¨åˆ°å°å­å›¾
- âš ï¸ ä¸²è¡Œç“¶é¢ˆï¼šè®­ç»ƒé˜¶æ®µæ— æ³•å¹¶è¡Œ

**é€‚ç”¨åœºæ™¯**ï¼š
- å­å›¾ç»“æ„ç›¸ä¼¼
- éœ€è¦å¿«é€Ÿè§£é‡Šå¤§é‡èŠ‚ç‚¹
- Training overhead å¯ä»¥æ¥å—

## å½“å‰é‡‡ç”¨æ–¹æ¡ˆï¼šAï¼ˆç‹¬ç«‹è®­ç»ƒï¼‰

### ä»£ç ä¿®æ”¹

```python
# benchmark_treecycle_distributed_v2.py Line 461
pg_result = run_pgexplainer_node(
    model=model_cpu,
    data=subgraph_cpu,  # Train on this specific subgraph
    target_node=int(target_node),
    epochs=30,
    lr=0.003,
    device='cpu',
    use_cache=False,  # âœ… KEY FIX: Disable cache
)
```

### æ€§èƒ½åˆ†æ

**æ—¶é—´åˆ†å¸ƒ**ï¼ˆæ¯ä¸ªä»»åŠ¡ï¼‰ï¼š
- PGExplainer è®­ç»ƒï¼š~15-20ç§’
- ç”Ÿæˆè§£é‡Šï¼š<1ç§’
- æ¨¡å‹è½¬ç§»ï¼ˆCPUâ†”GPUï¼‰ï¼š~0.5ç§’
- **æ€»è®¡**ï¼š~16-21ç§’/ä»»åŠ¡

**å¹¶è¡Œæ•ˆæœ**ï¼ˆ20 workersï¼‰ï¼š
- ä¸²è¡Œæ€»æ—¶é—´ï¼š100 tasks Ã— 20s = 2000s (33åˆ†é’Ÿ)
- å¹¶è¡Œå®é™…æ—¶é—´ï¼š100 tasks Ã· 20 workers Ã— 20s = 100s (1.7åˆ†é’Ÿ)
- **åŠ é€Ÿæ¯”**ï¼š~20x âœ…

**å¯¹æ¯”å…¶ä»–è§£é‡Šå™¨**ï¼š

| è§£é‡Šå™¨ | å¹³å‡æ—¶é—´/ä»»åŠ¡ | å¹¶è¡Œ | å¤‡æ³¨ |
|--------|--------------|------|------|
| ExhaustChase | 30-60s | âœ… | ç©·ä¸¾æœç´¢ |
| HeuChase | 20-40s | âœ… | å¯å‘å¼ |
| ApxChase | 10-25s | âœ… | è¿‘ä¼¼ç®—æ³• |
| GNNExplainer | 40-80s | âœ… | æ¢¯åº¦ä¼˜åŒ– |
| **PGExplainer** | **~20s** | **âœ…** | **å‚æ•°åŒ–ï¼ˆç‹¬ç«‹è®­ç»ƒï¼‰** |

**ç»“è®º**ï¼šPGExplainer åœ¨ç‹¬ç«‹è®­ç»ƒæ¨¡å¼ä¸‹ï¼Œæ€§èƒ½ä¸å…¶ä»–è§£é‡Šå™¨ç›¸å½“ï¼Œä¸”ä¿è¯äº†æ­£ç¡®æ€§ã€‚

## å¯¹æ¯”ï¼šç¼“å­˜ vs ç‹¬ç«‹è®­ç»ƒ

### é”™è¯¯çš„ç¼“å­˜å®ç°

```
Worker 0:
â”œâ”€ Task 1 (subgraph A, 500 nodes, 1000 edges)
â”‚  â”œâ”€ è®­ç»ƒ PGExplainer on A: 18s
â”‚  â”œâ”€ è§£é‡Š node X in A: <1s
â”‚  â””â”€ ç¼“å­˜ explainer_A
â”‚
â”œâ”€ Task 2 (subgraph B, 600 nodes, 1200 edges) 
â”‚  â”œâ”€ ä½¿ç”¨ explainer_A âŒ (trained on A, explaining B)
â”‚  â””â”€ è§£é‡Š node Y in B: <1s (é”™è¯¯ç»“æœï¼)
â”‚
â””â”€ Task 3 (subgraph C, 450 nodes, 900 edges)
   â”œâ”€ ä½¿ç”¨ explainer_A âŒ (trained on A, explaining C)
   â””â”€ è§£é‡Š node Z in C: <1s (é”™è¯¯ç»“æœï¼)

Total: 18s (è®­ç»ƒ) + 3s (è§£é‡Š) = 21s
ä½†ç»“æœé”™è¯¯ï¼åªæœ‰ Task 1 æ˜¯æ­£ç¡®çš„ã€‚
```

### æ­£ç¡®çš„ç‹¬ç«‹è®­ç»ƒ

```
Worker 0:
â”œâ”€ Task 1 (subgraph A, 500 nodes, 1000 edges)
â”‚  â”œâ”€ è®­ç»ƒ PGExplainer on A: 18s
â”‚  â””â”€ è§£é‡Š node X in A: <1s âœ…
â”‚
â”œâ”€ Task 2 (subgraph B, 600 nodes, 1200 edges)
â”‚  â”œâ”€ è®­ç»ƒ PGExplainer on B: 19s
â”‚  â””â”€ è§£é‡Š node Y in B: <1s âœ…
â”‚
â””â”€ Task 3 (subgraph C, 450 nodes, 900 edges)
   â”œâ”€ è®­ç»ƒ PGExplainer on C: 17s
   â””â”€ è§£é‡Š node Z in C: <1s âœ…

Total: (18+19+17)s + 3s = 57s
æ‰€æœ‰ç»“æœéƒ½æ˜¯æ­£ç¡®çš„ï¼
```

### 20 Workers å¹¶è¡Œ

```
å¹¶è¡Œ Makespan: 57s (Worker 0) vs 54s (Worker 1) vs ... 
å®é™…å®Œæˆæ—¶é—´ï¼š~60sï¼ˆæœ€æ…¢çš„ workerï¼‰

å¯¹æ¯”ç¼“å­˜ï¼ˆé”™è¯¯ï¼‰ï¼š
- Worker 0: 21s (2 ä¸ªç»“æœé”™è¯¯)
- Worker 1: 22s (2 ä¸ªç»“æœé”™è¯¯)
- ...
- å®é™…å®Œæˆæ—¶é—´ï¼š~25s
- ä½† 95% ç»“æœæ˜¯é”™è¯¯çš„ï¼âŒ
```

## é¢„æœŸè¾“å‡º

```
Worker 0: Task 1/5 (node 559700, 890 edges)...
Worker 0: PGExplainer using CPU (PyG multi-GPU workaround)
[PGExplainer] Training new explainer (cache disabled)  # â† æ³¨æ„ï¼šæ¯æ¬¡éƒ½è®­ç»ƒ
[PGExplainer] Training once on 454 nodes, 892 edges
[PGExplainer] Training with 100 sample nodes
[PGExplainer] Training completed after 30 epochs
Worker 0: Model restored to cuda:0
Worker 0: Task 1/5 âœ“ (18.23s)

Worker 0: Task 2/5 (node 253311, 1055 edges)...
Worker 0: PGExplainer using CPU (PyG multi-GPU workaround)
[PGExplainer] Training new explainer (cache disabled)  # â† å†æ¬¡è®­ç»ƒï¼ˆæ–°å­å›¾ï¼‰
[PGExplainer] Training once on 539 nodes, 1055 edges
[PGExplainer] Training with 100 sample nodes
[PGExplainer] Training completed after 30 epochs
Worker 0: Model restored to cuda:0
Worker 0: Task 2/5 âœ“ (19.45s)
```

**å…³é”®å˜åŒ–**ï¼š
- âŒ ä¸å†çœ‹åˆ° "Using cached trained explainer"
- âœ… æ¯ä¸ªä»»åŠ¡éƒ½æ˜¯ "Training new explainer"
- âœ… æ—¶é—´ ~18-20ç§’/ä»»åŠ¡ï¼ˆä¸€è‡´ï¼‰

## å®éªŒè®¾è®¡çš„æ„ä¹‰

### é—®é¢˜ï¼šä¸ºä»€ä¹ˆè¦æµ‹è¯• PGExplainerï¼Ÿ

PGExplainer æ˜¯ä¸€ä¸ªé‡è¦çš„åŸºå‡†ï¼š
1. **å‚æ•°åŒ–è§£é‡Šå™¨**ï¼šä»£è¡¨ä¸€ç±»éœ€è¦è®­ç»ƒçš„æ–¹æ³•
2. **å¯¹æ¯”éå‚æ•°æ–¹æ³•**ï¼švs HeuChase/ApxChase/ExhaustChase
3. **ç«¯åˆ°ç«¯å­¦ä¹ **ï¼šå­¦ä¹ è§£é‡Šç­–ç•¥ï¼Œè€ŒéåŸºäºè§„åˆ™

### æ­£ç¡®çš„å®éªŒè®¾ç½®

**ç‹¬ç«‹è®­ç»ƒï¼ˆå½“å‰ï¼‰**ï¼š
- æ¯ä¸ªå­å›¾ç‹¬ç«‹è®­ç»ƒ
- ä½“ç° PGExplainer çš„çœŸå®æˆæœ¬
- å…¬å¹³å¯¹æ¯”ï¼šæ‰€æœ‰è§£é‡Šå™¨éƒ½åœ¨å­å›¾ä¸Šè¿è¡Œ

**å¦‚æœä½¿ç”¨é›†ä¸­è®­ç»ƒ**ï¼š
- éœ€è¦åœ¨è®ºæ–‡ä¸­æ˜ç¡®è¯´æ˜
- ä¸èƒ½ç›´æ¥ä¸å…¶ä»–è§£é‡Šå™¨å¯¹æ¯”æ—¶é—´
- åº”è¯¥åˆ†å¼€æŠ¥å‘Šï¼štraining time + inference time

## æ€»ç»“

### ä¿®å¤å†…å®¹
- âœ… è®¾ç½® `use_cache=False`
- âœ… æ¯ä¸ªå­å›¾ç‹¬ç«‹è®­ç»ƒ PGExplainer
- âœ… ä¿è¯ç»“æœæ­£ç¡®æ€§

### æ€§èƒ½å½±å“
- â±ï¸ æ—¶é—´å¢åŠ ï¼š~20s/ä»»åŠ¡ï¼ˆvs é”™è¯¯çš„ <1sï¼‰
- âœ… ä½†ä¿è¯æ­£ç¡®æ€§ï¼
- âœ… 20x å¹¶è¡ŒåŠ é€Ÿä»ç„¶æœ‰æ•ˆ

### ä¸å…¶ä»–è§£é‡Šå™¨å¯¹æ¯”
- PGExplainer (~20s) ä¸ HeuChase (~30s) ç›¸å½“
- æ‰€æœ‰è§£é‡Šå™¨éƒ½åœ¨å­å›¾ä¸Šè¿è¡Œ
- å…¬å¹³çš„ç«¯åˆ°ç«¯å¯¹æ¯”

**è¿™æ˜¯ä¸€ä¸ªé‡è¦çš„ä¿®æ­£ï¼æ„Ÿè°¢ç”¨æˆ·çš„ä»”ç»†å®¡æŸ¥ã€‚** ğŸ¯
