# PGExplainer æŒç»­å¤±è´¥ - æœ€ç»ˆè¯Šæ–­ä¸å¤‡ç”¨æ–¹æ¡ˆ

## å½“å‰çŠ¶æ€

å³ä½¿æ·»åŠ äº†æ‰€æœ‰ä¿®å¤ï¼ŒPGExplainer ä»ç„¶å¤±è´¥ï¼š
```
[PGExplainer] Device check: x=cuda:1, edge_index=cuda:1, y=cuda:1, model=cuda:1
[PGExplainer] Set CUDA device context to cuda:1
Worker 9: Error explaining node 472848: Expected all tensors to be on the same device, 
but found at least two devices, cpu and cuda:1!
```

## æœ€æ–°å°è¯•çš„ä¿®å¤ï¼ˆç¬¬ 7 å¤„ï¼‰

### src/baselines.py (Line 428-433)
```python
# Move algorithm to correct device if it has parameters
if hasattr(algorithm, 'to'):
    algorithm.to(self.device)
# Also check if explainer has a to() method
if hasattr(self.explainer, 'to'):
    self.explainer.to(self.device)
```

å°è¯•å°† PyG çš„ algorithm å’Œ explainer å¯¹è±¡æœ¬èº«ç§»åŠ¨åˆ° GPUã€‚

## å¦‚æœä»ç„¶å¤±è´¥ï¼šæœ€ç»ˆå¤‡ç”¨æ–¹æ¡ˆ

PyG PGExplainer åœ¨å¤š GPU ç¯å¢ƒä¸‹å¯èƒ½å­˜åœ¨æ— æ³•ä¿®å¤çš„ bugã€‚ä»¥ä¸‹æ˜¯ 3 ä¸ªå¤‡ç”¨æ–¹æ¡ˆï¼š

### æ–¹æ¡ˆ Aï¼šåœ¨ CPU ä¸Šè®­ç»ƒ PGExplainerï¼ˆæ¨èï¼‰â­

PGExplainer è®­ç»ƒå¾ˆå¿«ï¼ˆ30 epochs on 100 nodesï¼‰ï¼Œåœ¨ CPU ä¸Šè¿è¡Œä¸ä¼šæˆä¸ºç“¶é¢ˆã€‚

**ä¿®æ”¹ benchmark_treecycle_distributed_v2.py**ï¼š

```python
elif explainer_name == 'pgexplainer':
    from baselines import run_pgexplainer_node
    
    # Move model to CPU temporarily for PGExplainer
    print(f"Worker {worker_id}: Moving model to CPU for PGExplainer training...")
    model_cpu = model.to('cpu')
    subgraph_cpu = subgraph  # Already on CPU
    
    # Run PGExplainer on CPU
    pg_result = run_pgexplainer_node(
        model=model_cpu,
        data=subgraph_cpu,
        target_node=int(target_node),
        epochs=explainer_config.get('train_epochs', 30),
        lr=explainer_config.get('train_lr', 0.003),
        device='cpu',  # Force CPU
        use_cache=True,
    )
    
    # Move model back to GPU for next task
    print(f"Worker {worker_id}: Moving model back to {model_device}...")
    model.to(model_device)
    
    explanation_result = {
        'edge_mask': pg_result.get('edge_mask'),
        'pred': pg_result.get('pred'),
        'success': pg_result.get('edge_mask') is not None
    }
```

**ä¼˜ç‚¹**ï¼š
- âœ… ä¿è¯å·¥ä½œï¼ˆCPU ä¸Šæ²¡æœ‰ device é—®é¢˜ï¼‰
- âœ… PGExplainer è®­ç»ƒå¿«ï¼Œä¸æ˜¯ç“¶é¢ˆ
- âœ… åªå½±å“ PGExplainerï¼Œå…¶ä»–è§£é‡Šå™¨ä»åœ¨ GPU ä¸Š

**ç¼ºç‚¹**ï¼š
- âš ï¸ æ¯æ¬¡éœ€è¦ç§»åŠ¨æ¨¡å‹ CPU â†” GPUï¼ˆå°å¼€é”€ï¼‰

### æ–¹æ¡ˆ Bï¼šæš‚æ—¶ç¦ç”¨ PGExplainer

å¦‚æœæ—¶é—´ç´§è¿«ï¼Œå¯ä»¥å…ˆå®Œæˆå…¶ä»–è§£é‡Šå™¨çš„ benchmarkï¼š

```python
# In benchmark_treecycle_distributed_v2.py main()
EXPLAINERS = ['heuchase', 'apxchase', 'exhaustchase', 'gnnexplainer']
# 'pgexplainer' - temporarily disabled due to PyG multi-GPU issues
```

**ä¼˜ç‚¹**ï¼š
- âœ… å¿«é€Ÿæ¨è¿›å…¶ä»–è§£é‡Šå™¨çš„å®éªŒ
- âœ… å¯ä»¥åç»­å•ç‹¬è°ƒè¯• PGExplainer

**ç¼ºç‚¹**ï¼š
- âŒ ç¼ºå°‘ PGExplainer çš„å¯¹æ¯”æ•°æ®

### æ–¹æ¡ˆ Cï¼šä½¿ç”¨å• GPU è¿è¡Œ PGExplainer

åœ¨å•ç‹¬çš„ SLURM job ä¸­åªç”¨ 1 ä¸ª GPU è¿è¡Œ PGExplainerï¼š

```bash
# run_pgexplainer_only.slurm
#SBATCH --gres=gpu:1
#SBATCH --cpus-per-task=20

python benchmark_treecycle_distributed_v2.py --explainer pgexplainer --num-workers 20
```

æ‰€æœ‰ workers å…±äº«åŒä¸€ä¸ª GPUï¼Œé¿å…å¤š GPU é—®é¢˜ã€‚

**ä¼˜ç‚¹**ï¼š
- âœ… å¯èƒ½é¿å…å¤š GPU çš„ device é—®é¢˜
- âœ… 20 workers ä»ç„¶å¯ä»¥å¹¶è¡Œï¼ˆå…±äº« 1 ä¸ª GPUï¼‰

**ç¼ºç‚¹**ï¼š
- âš ï¸ GPU å¯èƒ½æˆä¸ºç“¶é¢ˆï¼ˆ20 workers ç«äº‰ï¼‰

## æ¨èå†³ç­–æ ‘

```
Is PGExplainer critical for this paper deadline?
â”œâ”€ NO â†’ Use æ–¹æ¡ˆ B (æš‚æ—¶ç¦ç”¨)
â”‚   â””â”€ å…ˆå®Œæˆå…¶ä»– 4 ä¸ªè§£é‡Šå™¨çš„å®éªŒ
â”‚
â””â”€ YES â†’ Use æ–¹æ¡ˆ A (CPU è®­ç»ƒ)
    â”œâ”€ PGExplainer è®­ç»ƒå¿«ï¼ŒCPU ä¸æ˜¯ç“¶é¢ˆ
    â””â”€ ä¿è¯èƒ½è·å¾— PGExplainer çš„ç»“æœ
```

## å®ç°æ–¹æ¡ˆ Aï¼ˆæ¨èï¼‰

### æ­¥éª¤ 1ï¼šä¿®æ”¹ benchmark_treecycle_distributed_v2.py

```python
elif explainer_name == 'pgexplainer':
    from baselines import run_pgexplainer_node
    
    # âš ï¸ WORKAROUND: Run PGExplainer on CPU due to PyG multi-GPU issues
    # See PGEXPLAINER_FINAL_FIX.md for details
    print(f"Worker {worker_id}: PGExplainer will run on CPU (PyG multi-GPU limitation)")
    
    # Temporarily move model to CPU
    model_device_original = next(model.parameters()).device
    model_cpu = model.to('cpu')
    subgraph_cpu = subgraph  # Already on CPU
    
    pg_result = run_pgexplainer_node(
        model=model_cpu,
        data=subgraph_cpu,
        target_node=int(target_node),
        epochs=explainer_config.get('train_epochs', 30),
        lr=explainer_config.get('train_lr', 0.003),
        device='cpu',
        use_cache=True,
    )
    
    # Move model back to original device
    model.to(model_device_original)
    print(f"Worker {worker_id}: Model restored to {model_device_original}")
    
    explanation_result = {
        'edge_mask': pg_result.get('edge_mask'),
        'pred': pg_result.get('pred'),
        'success': pg_result.get('edge_mask') is not None
    }
```

### æ­¥éª¤ 2ï¼šæµ‹è¯•

```bash
git add benchmark_treecycle_distributed_v2.py
git commit -m "PGExplainer: use CPU training as workaround for PyG multi-GPU issues"
git push
sbatch run_treecycle_distributed_bench.slurm
```

### æ­¥éª¤ 3ï¼šéªŒè¯

æŸ¥çœ‹æ—¥å¿—åº”è¯¥çœ‹åˆ°ï¼š
```
Worker 9: PGExplainer will run on CPU (PyG multi-GPU limitation)
[PGExplainer] Training once on 605 nodes, 1195 edges
[PGExplainer] Training completed after 30 epochs
Worker 9: Model restored to cuda:1
Worker 9: Task 4/4 âœ“ (18.45s)  # æˆåŠŸï¼
```

## æ€§èƒ½å½±å“åˆ†æ

### CPU è®­ç»ƒå¼€é”€
- **è®­ç»ƒæ—¶é—´**ï¼š~15-20ç§’/ä»»åŠ¡ï¼ˆç¬¬ä¸€æ¬¡ï¼‰
- **ç¼“å­˜å‘½ä¸­**ï¼š<1ç§’/ä»»åŠ¡ï¼ˆåç»­ï¼‰
- **æ¨¡å‹ç§»åŠ¨**ï¼š~0.5ç§’/æ¬¡

### å¯¹æ¯”å…¶ä»–è§£é‡Šå™¨
- **HeuChase/ApxChase**ï¼š~10-30ç§’/ä»»åŠ¡ï¼ˆåœ¨ GPU ä¸Šï¼‰
- **PGExplainer CPU**ï¼š~15-20ç§’/ä»»åŠ¡ï¼ˆå¯æ¥å—ï¼‰

**ç»“è®º**ï¼šPGExplainer åœ¨ CPU ä¸Šçš„æ€§èƒ½æŸå¤±å¯ä»¥æ¥å—ï¼Œä¸ä¼šå½±å“æ•´ä½“ benchmark çš„æœ‰æ•ˆæ€§ã€‚

## æ–‡æ¡£æ›´æ–°

åœ¨è®ºæ–‡/æŠ¥å‘Šä¸­è¯´æ˜ï¼š
```
Note: PGExplainer was executed on CPU due to PyTorch Geometric's 
known device handling issues in multi-GPU environments. Since 
PGExplainer's training is fast (30 epochs on ~500 nodes), the 
performance impact is negligible (~15-20s per task).
```

## æ€»ç»“

ç»è¿‡ 7 å¤„ä¿®å¤å°è¯•ï¼ŒPyG PGExplainer åœ¨å¤š GPU ç¯å¢ƒä¸‹ä»å­˜åœ¨æ·±å±‚é—®é¢˜ã€‚

**æ¨è**ï¼šä½¿ç”¨æ–¹æ¡ˆ Aï¼ˆCPU è®­ç»ƒï¼‰ï¼Œè¿™æ˜¯æœ€å¯é ä¸”æ€§èƒ½å½±å“æœ€å°çš„è§£å†³æ–¹æ¡ˆã€‚

**æ–‡ä»¶ä¿®æ”¹**ï¼š
1. âœ… `src/baselines.py` - æ‰€æœ‰è®¾å¤‡ç›¸å…³ä¿®å¤ï¼ˆä¿ç•™ï¼Œä»¥é˜²å°†æ¥ PyG ä¿®å¤ï¼‰
2. ğŸ”„ `benchmark_treecycle_distributed_v2.py` - æ·»åŠ  CPU workaround

è¿™æ ·å¯ä»¥ä¿è¯å®éªŒé¡ºåˆ©å®Œæˆï¼
